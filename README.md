## GEEKFESTIA-2021
### DAY-1
Brushing up the basics, going through some python libraries.
______________________________________________________________________________________________________________________________________________________________________________
### DAY-2
<!---#### This repository contains a Data Analysis on a weather dataset created using Jupyter Notebook.
#### The weather dataset contains the following columns:- **year, month, day, hour, PM2.5(Particulate matter), temperature, pressure, rain, wind_direction, wind_speed.**  <p>
 <!--- <em> Pariculate matter :- PM stands for particulate matter (also called particle pollution): the term for a mixture of solid particles and liquid droplets found in the                             air. Some particles, such as dust, dirt, soot, or smoke, are large or dark enough to be seen with the naked eye. <p>
   Temperature :- Temperature is a degree of hotness or coldness the can be measured using a thermometer. <p>
   Pressure:- Atmospheric or air pressure is the force per unit of area exerted on the Earthâ€™s surface by the weight of the air above the surface. <p>
   Rain :- The condensed moisture of the atmosphere falling visibly in separate drops. <p>
   Wind direction :- Wind direction is defined as the direction the wind is coming from. If you stand so that the wind is blowing directly into your face, the direction                      you are facing names the wind.For general purposes, the wind direction is reported to eight compass points: N, NE, E, SE, S, SW, W, NW. <p>
   Wind speed :- In meteorology, wind speed, or wind flow speed, is a fundamental atmospheric quantity caused by air moving from high to low pressure, usually due to                      changes in temperature. <p> </em> 
#### Exploratory Data Analysis is an approach to analyze data, to summarize the main characteristics of data, and better understand the data set. It also allows us to quickly interpret the data and adjust different variables to see their effect. The three main steps to get a perfect EDA are :-
* Extracting/Downloading the data from an authorized source.
* Cleaning and processing the data 
* Performing data visualization on the cleaned data set.

#### We are going to analyze the Weather data set. <p>
Our main aim is to perform data cleaning, data normalizing, testing the hypothesis, and deriving appropriate insights. --->

#### 1. Importing the necessary libraries :<p>
   * Pandas, Numpy and Scikit-Learn 
 
#### 2. Reading the dataset : <p>
  * There are 31527 samples in the dataset.
  * All the Columns have a few NaN values.
  * Wind Direction is a categorical data with 16 categories representing various directions.

#### 3. Cleaning and Processing the Dataset : <p>
   * Convert all the numeric data from object data-type to float/int data-type.
   * Filled all the NaN values cells with suitable values.
   * Converted the given datetime data to Standard format.
   * Exported the cleaned data as Clean_Data.csv. 
 _________________________________________________________________________________________________________________________________________________________________________

### DAY-3 and DAY-4
   * Visualization of features using various graphs using matplotlib and seaborn.
   * Explained the observations from the graphs briefly.
   * Plotted the co-relation using heatmap.
__________________________________________________________________________

### DAY-5 and DAY-6
   * Prediction of PM2.5 using various models.
   * Tried ARIMA and VAR models, but both models failed to give satisfactory results.
   * So, atlast we had to use Random Forest Regressor.
___________________________________________________________________________
### Day 8-10
   * Created Web Application using Flask Framework.
   * Deployed the Model using Heroku
   * The model got deployed successfully, but doesn't run.
   * Link to the web-application- https://air-quality-prediction-gfg.herokuapp.com/

